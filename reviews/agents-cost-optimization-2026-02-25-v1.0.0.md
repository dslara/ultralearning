# üí∞ Revis√£o de Agentes: Otimiza√ß√£o de Custos

**Data**: 2026-02-25  
**Vers√£o**: v1.0.0  
**Gerado por**: @review  
**Tipo**: agents  
**Foco**: Redu√ß√£o de custo de tokens nos system prompts dos 3 agentes

---

## üìä Contexto: Como o Custo Funciona

**Custo por intera√ß√£o = tokens de entrada (system prompt + hist√≥rico + mensagem) + tokens de sa√≠da**

Os agentes s√£o **system prompts est√°ticos** lidos inteiros em toda intera√ß√£o.

| Agente | Linhas | Tamanho | Tokens estimados¬π | Custo input/chamada¬≤ | Frequ√™ncia de uso |
|--------|--------|---------|-------------------|---------------------|-------------------|
| @meta | 428 | ~11KB | ~2.800 tokens | ~$0.0084 | 10% das intera√ß√µes |
| @tutor | 491 | ~12KB | ~3.200 tokens | ~$0.0096 | 80% das intera√ß√µes |
| @review | 364 | ~12KB | ~3.100 tokens | ~$0.0093 | 10% das intera√ß√µes |

¬π *~350 tokens/KB de markdown t√©cnico*  
¬≤ *Claude Sonnet 4.6: $3/M input tokens*

**@tutor √© o agente com maior impacto de custo** ‚Äî maior em tokens E mais frequente.

**Nota de escala**: Para uso pessoal (5‚Äì10 sess√µes/semana), o custo absoluto √© pequeno (~$2‚Äì5/m√™s). O valor desta an√°lise √© arquitetural: boas pr√°ticas hoje evitam custos quando a frequ√™ncia escalar ou quando novos agentes forem criados.

---

## ‚ö†Ô∏è Problemas Identificados

### #1 [ALTO] Prompt Caching n√£o est√° sendo explorado

**O que √©**: Anthropic oferece prompt caching nativo. System prompts est√°ticos reutilizados t√™m custo de **10% do input normal** (90% de desconto) quando marcados como bloco cache√°vel na chamada de API.

**Situa√ß√£o atual**: Os 3 agentes t√™m conte√∫do 100% est√°tico entre sess√µes ‚Äî o caso ideal para caching. Mas:
- Nenhum agente documenta que √© eleg√≠vel para caching
- O `opencode` pode ou n√£o estar usando esta feature (requer verifica√ß√£o)
- O design atual n√£o garante que o conte√∫do est√°tico venha **antes** de conte√∫do din√¢mico (requisito para cache hits)

**Impacto estimado com caching ativo**:
- @tutor: 5 sess√µes/semana √ó 3.200 tokens ‚Üí 16.000 tokens/semana ‚Üí com cache: 1.600 tokens/semana
- Economia: ~$0.41/m√™s s√≥ no @tutor (insignificante hoje, multiplic√°vel por frequ√™ncia)

**Solu√ß√£o**:
1. Verificar se o `opencode` usa a API de prompt caching da Anthropic
2. Adicionar na `Identidade` de cada agente: `**Cache**: System prompt est√°tico ‚Äî eleg√≠vel para prompt caching`
3. Garantir que o sistema prompt seja enviado antes de qualquer conte√∫do din√¢mico (j√° √© o caso hoje)

---

### #2 [M√âDIO] Se√ß√£o "Exemplos de Intera√ß√£o" duplica conte√∫do das keywords

**Situa√ß√£o**: A se√ß√£o `üéØ Exemplos de Intera√ß√£o` no final de @meta e @tutor repete exemplos de keywords que j√° t√™m os seus pr√≥prios exemplos inline.

**@tutor** (linhas 400‚Äì440, ~40 linhas / ~200 tokens):
- Mostra `#quiz 3 perguntas sobre FastAPI` ‚Üí j√° coberto em `### #quiz` (linhas 138‚Äì156)
- Mostra `#directness Criar sistema de login` ‚Üí j√° coberto em `### #directness` (linhas 54‚Äì75)
- Mostra `#feynman JWT` ‚Üí j√° coberto em `### #feynman` (linhas 88‚Äì98)

**@meta** (linhas 341‚Äì370, ~30 linhas / ~150 tokens):
- Mostra `#decompose-goal` ‚Üí j√° coberto na keyword (linhas 62‚Äì119)
- Mostra `#create-weekly-plan semana 3` ‚Üí j√° coberto na keyword (linhas 160‚Äì203)

**Total de tokens duplicados**: ~350 tokens por chamada a @tutor ou @meta.

**O que a se√ß√£o deveria ser** (se mantida): Exemplos de **composi√ß√£o entre keywords** ou **fluxos completos** ‚Äî algo que os exemplos isolados das keywords n√£o mostram. Ex: "usu√°rio come√ßa com `#quiz`, erra conceito, √© direcionado para `#feynman`".

**Solu√ß√£o**: Substituir exemplos duplicados por 1‚Äì2 exemplos de fluxo composto, ou remover a se√ß√£o completamente.

---

### #3 [M√âDIO] Output sem instru√ß√£o de concis√£o expl√≠cita

**O problema**: Output tokens custam 3‚Äì8x mais que input tokens no Sonnet. Os agentes instruem **comportamento** (socr√°tico, planeja, revisa) mas n√£o instruem **tamanho de output**.

**Keywords com risco de verbosidade desnecess√°ria**:

| Keyword | Output ideal | Risco sem instru√ß√£o |
|---------|-------------|---------------------|
| `#quiz N perguntas` | N perguntas, 1‚Äì2 linhas cada | Adicionar contexto, dicas, explica√ß√µes |
| `#zombie` | 3 micro-passos, ~8 linhas | Virar motivational speech de 30 linhas |
| `#diffuse` | 4 passos, ~8 linhas | Idem |
| `#habit-stack` | 3 h√°bitos encadeados, ~10 linhas | Explica√ß√£o longa sobre Atomic Habits |
| `#review-structure` | An√°lise direta com problemas listados | Relat√≥rio de 200 linhas sem necessidade |

**Solu√ß√£o por agente**:
- **@tutor** ‚Äî adicionar ao Checklist Final: `[ ] Resposta est√° no tamanho m√≠nimo? (sem explica√ß√µes n√£o solicitadas)`
- **@meta** ‚Äî adicionar √† Miss√£o: "outputs seguem os templates definidos ‚Äî n√£o expandir al√©m do formato"
- **@review** ‚Äî adicionar ao Checklist Final: `[ ] O relat√≥rio est√° na densidade certa? (problemas + evid√™ncia + solu√ß√£o, sem padding)`

---

### #4 [BAIXO] @review induz carregamento de contexto n√£o-seletivo

**Situa√ß√£o**: A se√ß√£o `üß≠ Contexto e Continuidade` do @review lista v√°rios arquivos a verificar antes de revisar. Isso √© correto para `#audit-quality`, mas para keywords espec√≠ficas como `#review-makefile` ou `#review-consistency`, carregar `reviews/README.md` + `planning/` + `scripts/` + `agents/` √© excessivo.

**Custo indireto**: O agente induz o usu√°rio a trazer mais contexto do que o necess√°rio para a keyword invocada, inflando o contexto da conversa.

**Solu√ß√£o**: Adicionar instru√ß√£o na se√ß√£o:
> "Solicite ao usu√°rio apenas os arquivos relevantes para a keyword invocada. N√£o pe√ßa tudo de uma vez."

---

### #5 [ESTRAT√âGICO] Model routing: Sonnet para todas as keywords independente de complexidade

**Situa√ß√£o**: Os 3 agentes declaram `Claude Sonnet 4.6`. Mas a complexidade cognitiva das keywords varia muito:

| Complexidade | Keywords | Modelo adequado | Custo relativo |
|-------------|----------|-----------------|---------------|
| **Baixa** (gera√ß√£o mec√¢nica) | `#quiz`, `#drill`, `#zombie`, `#diffuse`, `#habit-stack` | Haiku 3.5 | ~6x mais barato |
| **M√©dia** (racioc√≠nio guiado) | `#feynman`, `#feedback`, `#debug`, `#scaffold` | Sonnet ‚úÖ | baseline |
| **Alta** (an√°lise estrat√©gica) | `#decompose-goal`, `#review-architecture`, `#audit-quality`, `#intuition` | Sonnet ‚úÖ | baseline |

**Estimativa**: ~35‚Äì40% das intera√ß√µes com @tutor s√£o keywords de complexidade baixa.

**Trade-off importante**: Model routing adiciona complexidade ao workflow (`make study` teria que escolher o modelo). Para uso pessoal com volume baixo, o ROI n√£o justifica agora. Mas √© uma alavanca dispon√≠vel se o uso escalar.

**Solu√ß√£o poss√≠vel (sem mudar os agentes)**:
- Criar `make study-fast` que invoca @tutor com Haiku para `#quiz`, `#drill`, `#zombie`, `#diffuse`
- Os arquivos de agente n√£o precisariam mudar ‚Äî s√≥ o script de invoca√ß√£o

---

## üìã Resumo de Impacto

| # | Problema | Impacto de Custo | Esfor√ßo | Recomenda√ß√£o |
|---|----------|-----------------|---------|--------------|
| 1 | Prompt Caching n√£o explorado | **Alto** ‚Äî 90% dos tokens input | Baixo (verificar config) | ‚úÖ Implementar agora |
| 2 | Exemplos duplicados em @meta e @tutor | M√©dio ‚Äî ~350 tokens/chamada | Baixo (editar ~70 linhas) | ‚úÖ Implementar agora |
| 3 | Output sem instru√ß√£o de concis√£o | **Alto** ‚Äî output custa 3‚Äì8x mais | Baixo (1 linha por agente) | ‚úÖ Implementar agora |
| 4 | @review induz contexto n√£o-seletivo | Baixo-M√©dio ‚Äî contexto inflado | Baixo (1 instru√ß√£o) | ‚úÖ Implementar agora |
| 5 | Model routing n√£o implementado | **Alto potencial** ‚Äî 6x em tasks simples | Alto (mudan√ßa arquitetural) | ‚è≥ Avaliar quando uso escalar |

---

## üéØ A√ß√µes Recomendadas

### Imediato (mudan√ßas nos arquivos `.md` dos agentes)

1. **[Agora ‚Äî @tutor]** Substituir se√ß√£o `üéØ Exemplos de Intera√ß√£o` por 1 exemplo de fluxo composto
2. **[Agora ‚Äî @meta]** Idem ‚Äî substituir exemplos duplicados por fluxo composto
3. **[Agora ‚Äî todos]** Adicionar instru√ß√£o de concis√£o no `‚ö†Ô∏è Checklist Final`:
   - @tutor: `[ ] Resposta no tamanho m√≠nimo? (sem explica√ß√µes n√£o solicitadas)`
   - @meta: `[ ] Output segue o template definido sem expans√£o desnecess√°ria?`
   - @review: `[ ] Relat√≥rio na densidade certa? (sem padding entre problema/evid√™ncia/solu√ß√£o)`
4. **[Agora ‚Äî todos]** Adicionar em `Identidade`: `**Cache**: System prompt est√°tico ‚Äî eleg√≠vel para prompt caching`
5. **[Agora ‚Äî @review]** Adicionar em `üß≠ Contexto e Continuidade`: nota sobre solicitar apenas arquivos relevantes para a keyword invocada

### Verifica√ß√£o t√©cnica (fora dos arquivos de agente)

6. **[Curto prazo]** Verificar se o `opencode` envia chamadas com `cache_control` para system prompts ‚Äî esta √© a maior alavanca de custo dispon√≠vel

### Estrat√©gico (mudan√ßa arquitetural)

7. **[Longo prazo]** Avaliar `make study-fast` com model routing para keywords de baixa complexidade no @tutor

---

## üí° Padr√µes Gerais Aprendidos

Para refer√™ncia ao criar novos agentes (como @coach, @session):

| Padr√£o | Impacto | Como aplicar |
|--------|---------|--------------|
| **Prompt Caching** | 50‚Äì90% input | System prompt est√°tico ‚Üí cache eleg√≠vel |
| **Sem duplica√ß√£o** | 5‚Äì15% tamanho | 1 exemplo por keyword, sem se√ß√£o de repeti√ß√£o |
| **Instru√ß√£o de concis√£o** | 20‚Äì40% output | 1 linha no Checklist Final √© suficiente |
| **Output tokens > Input tokens** | 3‚Äì8x custo | Priorizar restri√ß√£o de output sobre compress√£o de input |
| **Model routing** | At√© 6x custo | Reservar modelos pesados para an√°lise; leves para gera√ß√£o mec√¢nica |
| **Contexto seletivo** | Vari√°vel | Pedir s√≥ o necess√°rio para a tarefa atual |

---

*Gerado por @review em 2026-02-25*
