# üìÖ Semana 54-55: CPU & Cache üî¨

## üéØ Objetivo
Ao final destas duas semanas, voc√™ ser√° capaz de:
- Entender ciclo fetch-decode-execute
- Explicar hierarquia de cache
- Otimizar c√≥digo para cache locality
- Medir impacto de cache misses

---

## ‚ùì Perguntas Guia

### CPU Basics
1. O que √© uma CPU?
2. O que s√£o registradores?
3. O que √© o ciclo fetch-decode-execute?
4. O que √© clock speed?
5. O que s√£o cores?

### Mem√≥ria
6. Por que n√£o usar s√≥ registradores?
7. Por que RAM √© lenta comparada a CPU?
8. O que √© lat√™ncia de mem√≥ria?
9. Quantos ciclos de clock para acessar RAM?

### Cache
10. O que √© cache?
11. Por que cache existe?
12. O que s√£o L1, L2, L3 cache?
13. Quais os tamanhos t√≠picos de cada n√≠vel?
14. Qual a lat√™ncia de cada n√≠vel?
15. O que √© cache line?
16. Qual o tamanho t√≠pico de cache line?

### Cache Locality
17. O que √© temporal locality?
18. O que √© spatial locality?
19. Por que acessar array sequencialmente √© r√°pido?
20. Por que linked list √© cache-unfriendly?
21. O que √© false sharing?

### Cache Misses
22. O que √© cache hit vs miss?
23. O que √© hit rate?
24. Quais os tipos de cache miss?
25. Como medir cache misses?

### Otimiza√ß√£o
26. O que √© loop tiling?
27. Como otimizar matrix multiplication para cache?
28. Por que ordem de loop importa?
29. O que √© data-oriented design?

---

## üìö Recursos

### Leitura Obrigat√≥ria
| Recurso | Se√ß√£o | Prop√≥sito |
|---------|-------|-----------|
| "What Every Programmer Should Know About Memory" | Ulrich Drepper | Deep dive |
| CSAPP | Chapter 6 - Memory Hierarchy | Fundamentos |

### üìñ Leitura Complementar (Recomendado)
**"Code: The Hidden Language of Computer Hardware and Software"** - Charles Petzold (2022 Edition)
- **Quando ler**: Antes ou durante esta semana
- **Foco**: Cap√≠tulos sobre portas l√≥gicas, rel√©s, constru√ß√£o de CPU
- **Por qu√™**: D√° intui√ß√£o bottom-up de como CPUs funcionam desde o hardware
- **Timing**: ~5-10h de leitura (pode dividir em 2 semanas)
- **Link**: https://www.amazon.es/dp/B0B123P5GV (‚Ç¨20.49)
- **Nota**: N√£o √© obrigat√≥rio, mas complementa MUITO bem esta fase

### Ferramentas
| Recurso | Prop√≥sito |
|---------|-----------|
| `perf` (Linux) | Medir cache misses |
| Instruments (Mac) | Profiling |

---

## üìã Entregas

### Semana 54: Fundamentos

**Dia 1: CPU Basics**
- [ ] Responder perguntas 1-5
- [ ] Pesquisar: specs do seu CPU
- [ ] O que s√£o instruction pipelines?
- [ ] O que √© out-of-order execution?

**Dia 2: Mem√≥ria**
- [ ] Responder perguntas 6-9
- [ ] Pesquisar: lat√™ncia t√≠pica de RAM
- [ ] Calcular: quantas instru√ß√µes CPU executa durante um acesso a RAM?
- [ ] Por que isso √© problema?

**Dia 3: Cache Hierarchy**
- [ ] Responder perguntas 10-16
- [ ] Descobrir tamanhos de cache do seu CPU
- [ ] Desenhar diagrama da hierarquia
- [ ] Comparar lat√™ncias de cada n√≠vel

**Dia 4: Cache Locality**
- [ ] Responder perguntas 17-21
- [ ] Exemplo de temporal locality
- [ ] Exemplo de spatial locality
- [ ] Por que arrays s√£o cache-friendly?

**Dia 5: Experimento**
- [ ] Benchmark: acessar array sequencial vs random
- [ ] Benchmark: row-major vs column-major em matrix
- [ ] Medir diferen√ßa de tempo
- [ ] Explicar resultados

### Semana 55: Otimiza√ß√£o

**Dia 1: Cache Misses**
- [ ] Responder perguntas 22-25
- [ ] Aprender a usar profiler
- [ ] Medir cache misses em programa
- [ ] Identificar hotspots

**Dia 2: Otimiza√ß√µes B√°sicas**
- [ ] Responder perguntas 26-28
- [ ] Implementar matrix multiplication naive
- [ ] Implementar com loop tiling
- [ ] Medir diferen√ßa

**Dia 3: Data-Oriented Design**
- [ ] Responder pergunta 29
- [ ] Comparar: Array of Structs vs Struct of Arrays
- [ ] Quando cada um √© melhor?
- [ ] Exemplo pr√°tico

**Dia 4: Projeto**
- [ ] Implementar programa cache-optimized
- [ ] Comparar: linked list vs array
- [ ] Medir com profiler
- [ ] Documentar findings

**Dia 5: Consolida√ß√£o**
- [ ] Responder TODAS as perguntas guia
- [ ] Criar cheat sheet de otimiza√ß√£o
- [ ] Cards SRS para lat√™ncias e conceitos
- [ ] Resumo: como pensar sobre cache

---

## ‚úÖ Crit√©rios de Sucesso

### Voc√™ dominou se consegue:
1. [ ] Explicar hierarquia de cache
2. [ ] Prever se c√≥digo √© cache-friendly
3. [ ] Medir cache misses
4. [ ] Otimizar loop para cache
5. [ ] Explicar por que arrays s√£o r√°pidos

### Lat√™ncias para Lembrar

| Opera√ß√£o | Lat√™ncia (aprox) |
|----------|------------------|
| L1 cache | ~1 ns |
| L2 cache | ~4 ns |
| L3 cache | ~20 ns |
| RAM | ~100 ns |
| SSD | ~100 ¬µs |
| HDD | ~10 ms |

### Red flags (precisa revisar):
- N√£o sabe o que √© cache line
- N√£o entende spatial locality
- N√£o consegue medir performance

---

## üîÑ Reflex√£o

### Trade-offs
_Como cache afeta design de estruturas de dados?_

### Pr√°tica
_Como voc√™ pensa diferente sobre performance agora?_

### Conex√£o
_Como isso explica performance de Vec vs LinkedList?_

---

## ‚è≠Ô∏è Pr√≥ximo

**Semana 56-57**: OS - Processos
- O que √© um processo?
- O que √© um thread?
- Como OS decide quem executa?
